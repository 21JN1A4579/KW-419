# -*- coding: utf-8 -*-
"""customer segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hmdN5wedxsbo2SQ6qqu2GI3rVfKAD85u

## **INTRODUCTION**

k-means clustering is one of the simplest clustering algorithm. Despite of its simplicity,k-means is vastly used for clustering in many data science applications,especially useful if you need to quickly discover insights from unlabelled data.

some real world applications of k-means include:
1.customer segmentation
2.document classification
3.delivery store optimization
4.image segmentation.
"""

import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle

"""imagine that you have a customer dataset,and you are interested in exploring the behaviour of your customers using their historical data.

Customer Segmentation is the practise of partioning a customer base into group of individuals that have similar characteristics.it is  a signifiacnt strategy as a bussiness can target these specific groups of customers and effectively allocate marketing resources.for example,one group might contain customers who are high profit and low risk i.e more likely to purchase products or subscribe to a service.A bussiness task is to retail those customers.another group might include customers from non profit organisations and so on...

## **load dataset**
"""

data=pd.read_csv("customer segmentation.csv")

data.columns

data.head()

"""## **data preprocessing**

As you can see,adress in this dataset is a categorical variable.k-means algorithm isn't directly applicable to categorical variables because euclidian distance function isn't really meaningful for discrete variables.so let's drop these feature and run clustering.
"""

df=data.drop("Address",axis=1)
df.head()

df.shape

df.info()

df.describe()

df.tail()

df.isnull()

df.duplicated()

"""now lets normalize the dataset.but why do we need normalization in the first place?
Normalization is a statistical method that help mathematical based algorithms interpret features with different magnitudes and distributions equally.we use "standardscaler()" to normalize our dataset.
"""

from sklearn.preprocessing import StandardScaler

x=df.values[:,1:]
x=np.nan_to_num(x)
scaled_dataset=StandardScaler().fit_transform(x)
scaled_dataset

"""## **Modeling**

let's run our model and group our customers into three clusters
*n_int:number of times the k-means algorithm will be run with different centroid seeds.the final result will be the best output of n_init consecutive runs in terms of inertia.
"""

from sklearn.cluster import KMeans
num_clusters = 3
k_means = KMeans(n_clusters=num_clusters, n_init=12)
k_means.fit(scaled_dataset)
labels = k_means.labels_
print(labels)

"""## **insights**

note that each row in our dataset represents  a customer and therefore each row is assigned as label.
"""

df["labels"]=labels
df.head()

"""we can easily check the centroid values by averaging the features in each cluster."""

df.groupby("labels").mean()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
sns.scatterplot(x=df["labels"], y=df["Other Debt"], palette=['g', 'r', 'c'])
plt.show()

plt.figure(figsize=(10, 8))
sns.barplot(x=df["labels"], y=df["Other Debt"], palette=['g', 'r', 'c'])
plt.show()

with open("kmeans_model.pkl", "wb") as f:
    pickle.dump(k_means, f)

with open("kmeans_model.pkl", "rb") as f:
    loaded_kmeans_model = pickle.load(f)